{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f3a0ec-8abd-4f9a-8fa3-42854a59e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import seaborn as sns### visualizations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "from datetime import datetime\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
    "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
    "                                     RandomContrast, Rescaling, Resizing, Reshape, LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
    "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5c8027-246a-4feb-b374-d18deb8a05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950e7e61-b68f-44b0-8a02-c1c3cebc3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                         boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                         boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                         boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                        axis=-1)\n",
    "\n",
    "    boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                         boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                         boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                         boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                        axis=-1)\n",
    "    lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "    rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "    square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "    square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8e9e1a-09d2-4349-8170-daa4aacc2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(x,y):\n",
    "  return tf.reduce_sum(tf.square(y-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7b8bea-fb0f-4b25-9be1-0713a7100716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(y_true, y_pred):\n",
    "  target = y_true[...,0]\n",
    "\n",
    "  ###################### OBject Loss\n",
    "  y_pred_extract = tf.gather_nd(y_pred, tf.where(target[:]==1))\n",
    "  y_target_extract = tf.gather_nd(y_true, tf.where(target[:]==1))\n",
    "  \n",
    "  rescaler = tf.where(target[:]==1)*SPLIT_SIZE\n",
    "  upscaler_1 = tf.concat([rescaler[:,1:],tf.zeros([len(rescaler),2], dtype=tf.int64)],axis=-1)\n",
    "  \n",
    "  target_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
    "                       repeats=[len(rescaler)], axis=0)*tf.cast(y_target_extract[...,1:5], dtype = tf.float32)\n",
    "  pred_1_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
    "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,1:5], dtype = tf.float32)\n",
    "  pred_2_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
    "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,6:10], dtype = tf.float32)\n",
    "  \n",
    "  target_orig = tf.cast(upscaler_1, dtype = tf.float32)+target_upscaler_2\n",
    "  pred_1_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_1_upscaler_2\n",
    "  pred_2_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_2_upscaler_2\n",
    "  \n",
    "  mask =tf.cast(tf.math.greater(compute_iou(target_orig,pred_2_orig),\n",
    "                                         compute_iou(target_orig,pred_1_orig)),dtype=tf.int32)\n",
    "  \n",
    "  y_pred_joined=tf.transpose(tf.concat([tf.expand_dims(y_pred_extract[...,0],axis=0),\n",
    "                        tf.expand_dims(y_pred_extract[...,5],axis=0)],axis=0))\n",
    "  \n",
    "  obj_pred = tf.gather_nd(y_pred_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
    "  \n",
    "  object_loss = difference(tf.cast(obj_pred,dtype =tf.float32)\n",
    "                            ,tf.cast(tf.ones([len(rescaler)]),dtype=tf.float32))\n",
    "\n",
    "  ####################### For No object\n",
    "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==0))\n",
    "  y_target_extract = tf.zeros(len(y_pred_extract))\n",
    "\n",
    "  no_object_loss_1 = difference(tf.cast(y_pred_extract[...,0],dtype =tf.float32)\n",
    "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
    "  \n",
    "  no_object_loss_2 = difference(tf.cast(y_pred_extract[...,5],dtype =tf.float32)\n",
    "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
    "  \n",
    "  no_object_loss = no_object_loss_1+no_object_loss_2\n",
    "\n",
    "  ######################## For OBject class loss\n",
    "  y_pred_extract = tf.gather_nd(y_pred[...,10:],tf.where(target[:]==1))\n",
    "  class_extract = tf.gather_nd(y_true[...,5:],tf.where(target[:]==1))\n",
    "\n",
    "  class_loss = difference(tf.cast(y_pred_extract,dtype =tf.float32)\n",
    "                                ,tf.cast(class_extract,dtype=tf.float32))\n",
    "\n",
    "  ######################### For object bounding box loss\n",
    "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==1))\n",
    "  centre_joined=tf.stack([y_pred_extract[...,1:3],y_pred_extract[...,6:8]],axis=1)\n",
    "  centre_pred = tf.gather_nd(centre_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
    "  centre_target = tf.gather_nd(y_true[...,1:3], tf.where(target[:]==1))\n",
    "  \n",
    "  centre_loss = difference(centre_pred,centre_target)\n",
    "    \n",
    "  size_joined=tf.stack([y_pred_extract[...,3:5],y_pred_extract[...,8:10]],axis=1)\n",
    "\n",
    "  size_pred = tf.gather_nd(size_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
    "  size_target = tf.gather_nd(y_true[...,3:5], tf.where(target[:]==1))\n",
    "  \n",
    "  size_loss = difference(tf.math.sqrt(tf.math.abs(size_pred)),tf.math.sqrt(tf.math.abs(size_target)))\n",
    "  box_loss = centre_loss+size_loss\n",
    "  \n",
    "  lambda_coord = 5.0\n",
    "  lambda_no_obj = 0.5\n",
    "\n",
    "  loss = object_loss + (lambda_no_obj*no_object_loss)+ tf.cast(lambda_coord*box_loss,dtype=tf.float32)+ tf.cast(class_loss,dtype=tf.float32) \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11642031-b166-4633-8c17-15384075b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable',\n",
    "         'dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d26e076-0274-4b77-83e6-843465bcce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"pascal_voc_2012_yolo_efficientnetB1.h5\", custom_objects={\"yolo_loss\": yolo_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8e1909-ff6f-4004-af20-9bdb44123bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"dataset/VOC2012/ValJPEGImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f798099-b61a-46be-ad00-de5619f85b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7a6756-d89f-4e41-a795-17efa6097aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bf190d-571b-40e9-8c2c-5d37ccee89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(filename):\n",
    "    try:\n",
    "        test = test_path+filename\n",
    "        # print(test)\n",
    "\n",
    "        img=cv2.resize(cv2.imread(test),(H,W))\n",
    "        \n",
    "        image = tf.io.decode_jpeg(tf.io.read_file(test))\n",
    "        image = tf.cast(tf.image.resize(image, [H, W]), dtype=tf.float32)\n",
    "        output = model.predict(tf.expand_dims(image, axis=0))\n",
    "        # print(output.shape)\n",
    "    \n",
    "        THRESH = .25\n",
    "    \n",
    "        # the object posistions is to get the first two (B) 5 values where eg. 0/1, norm_x_center, norm_y_center, norm_w, norm_h\n",
    "        # based on the defined threshold\n",
    "        object_positions=tf.concat([tf.where(output[...,0] >= THRESH), tf.where(output[...,5] >= THRESH)], axis=0)\n",
    "        # print(object_positions)\n",
    "        selected_output=tf.gather_nd(output, object_positions)\n",
    "        # print(selected_output)\n",
    "        final_boxes=[]\n",
    "        final_scores=[]\n",
    "\n",
    "        for i, pos in enumerate(object_positions):\n",
    "            # to loop the two (B) labels\n",
    "            for j in range(2):\n",
    "                # to get each of the first (label -- 0 to 1) of the five values\n",
    "                # selected_output[0][0] & selected_output[0][5]\n",
    "                if selected_output[i][j*5] > THRESH:\n",
    "                    # output[pos[0]][pos[1]][pos[2]] -- this is to get the 30 values output\n",
    "                    # [(j*5)+1:(j*5)+5] -- this is to get two (b) bounding box from the 30 values output\n",
    "                    # first loop -- [(0*5)+1]:(0*5)+5] -- [1:5]\n",
    "                    # second loop -- [(1*5)+1:(1*5)+5] -- [6:10]\n",
    "                    output_box = tf.cast(output[pos[0]][pos[1]][pos[2]][(j*5)+1:(j*5)+5], dtype=tf.float32)\n",
    "                    # print(output_box)\n",
    "\n",
    "                    # to get the x_centre, since the grid is 7 * 7 and the image size is 224\n",
    "                    # need to get the position of the object first which is from pos\n",
    "                    # pos/7*224 = pos*32 (224/7=32)\n",
    "                    # pos*32 + value*32 = (pos + value) * 32\n",
    "                    x_centre=(tf.cast(pos[1], dtype=tf.float32) + output_box[0])*32\n",
    "                    y_centre=(tf.cast(pos[2], dtype=tf.float32) + output_box[1])*32\n",
    "                    # print(x_centre)\n",
    "                    # print(y_centre)\n",
    "\n",
    "                    x_width, y_height = tf.math.abs(W * output_box[2]), tf.math.abs(H * output_box[3])\n",
    "\n",
    "                    # this is taking the bounding box's width/height to get the min and max coordinates \n",
    "                    # with the centre point of the bounding box\n",
    "                    x_min, y_min = int(x_centre-(x_width/2)), int(y_centre-(y_height/2))\n",
    "                    x_max, y_max = int(x_centre+(x_width/2)), int(y_centre+(y_height/2))\n",
    "\n",
    "                    x_min = 0 if x_min <= 0 else x_min\n",
    "                    y_min = 0 if y_min <= 0 else y_min\n",
    "                    x_max = W if x_max >= W else x_max\n",
    "                    y_max = H if y_max >= H else y_max\n",
    "\n",
    "                    final_boxes.append([x_min, \n",
    "                                        y_min, \n",
    "                                        x_max, \n",
    "                                        y_max, \n",
    "                                        str([classes[tf.argmax(selected_output[...,10:], axis=-1)[i]]])])\n",
    "\n",
    "                    final_scores.append(selected_output[i][j*5])\n",
    "        # print(final_scores)\n",
    "        # print(\"Final Box: \", final_boxes)\n",
    "        final_boxes = np.array(final_boxes)\n",
    "\n",
    "        object_classes = final_boxes[...,4]\n",
    "        nms_boxes = final_boxes[...,0:4]\n",
    "\n",
    "        # this is to remove the duplicate bounding boxes and remain the one with highest probability score\n",
    "        nms_output = tf.image.non_max_suppression(\n",
    "            nms_boxes, # containing the bounding box, in order to calculate the area\n",
    "            final_scores, # containing the first and the sixth value of the label, in order to get the highest score\n",
    "            max_output_size=100, # depending on the specific task, if there is 150 classes, then set to 150\n",
    "            iou_threshold=0.2, # using the larger bounding box to divide the duplicated box, if greater than 0.2 then discard it\n",
    "            score_threshold=float('-inf') # this is the threshold that if the score is lower than the defined, directly discard\n",
    "        )\n",
    "\n",
    "        # print(nms_output)\n",
    "\n",
    "        for i in nms_output:\n",
    "            cv2.rectangle(img, \n",
    "                          (int(final_boxes[i][0]), int(final_boxes[i][1])), \n",
    "                          (int(final_boxes[i][2]), int(final_boxes[i][3])), \n",
    "                          (255,0,0), \n",
    "                          1)\n",
    "\n",
    "            cv2.putText(img,\n",
    "                        final_boxes[i][-1],\n",
    "                        (int(final_boxes[i][0]), int(final_boxes[i][1])+15),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL, \n",
    "                        1, \n",
    "                        (0,0,0), \n",
    "                        1)\n",
    "\n",
    "        cv2.imwrite(\"output/\" + filename[:-4] + \"_det.jpg\", cv2.resize(img, (384,384)))\n",
    "            \n",
    "    except:\n",
    "        print(\"No Object Found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1fd7801-47d7-4ea9-833e-e2813b2f48aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/val2017/000000000139.jpg\n",
      "(1, 7, 7, 30)\n",
      "tf.Tensor(\n",
      "[[0 3 4]\n",
      " [0 4 4]\n",
      " [0 0 3]\n",
      " [0 3 4]\n",
      " [0 4 4]], shape=(5, 3), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[3.9771909e-01 6.5087509e-01 4.3916300e-01 2.3826581e-01 3.2411438e-01\n",
      "  4.6929896e-01 5.6332964e-01 4.5645911e-01 1.1285289e-01 1.9790517e-01\n",
      "  5.2837916e-03 2.6853201e-03 1.8878145e-03 3.8372127e-03 4.2474237e-03\n",
      "  1.5914055e-03 2.3122712e-03 4.4010924e-03 2.7509305e-01 7.5809103e-03\n",
      "  4.8044147e-03 3.5881207e-03 1.5113264e-03 6.3503149e-04 5.6665337e-01\n",
      "  1.8790988e-02 4.2701536e-03 8.5225161e-03 7.2963891e-04 1.6405111e-02]\n",
      " [6.3112724e-01 4.7805014e-01 4.1215324e-01 9.9348441e-02 1.9270043e-01\n",
      "  7.0542997e-01 4.5462221e-01 4.2997396e-01 2.2061114e-01 3.0477968e-01\n",
      "  7.7536292e-03 3.1222547e-03 1.9102831e-03 6.0180826e-03 2.2914133e-03\n",
      "  4.6955612e-03 3.7736509e-03 6.9671529e-03 3.4356844e-01 2.5895773e-03\n",
      "  9.6747343e-04 3.2366079e-03 1.3682389e-03 1.5522166e-03 4.9770910e-01\n",
      "  2.5655344e-02 5.3435043e-03 3.5018433e-02 1.9784782e-03 9.3930336e-03]\n",
      " [2.2983435e-01 4.8635995e-01 6.7731017e-01 6.4063549e-02 1.6988099e-01\n",
      "  4.0888035e-01 5.6595588e-01 5.6263459e-01 1.8342373e-01 2.3199788e-01\n",
      "  1.6943045e-02 1.3388705e-03 2.8528839e-03 1.6997287e-02 2.8260738e-02\n",
      "  1.2860303e-02 1.8140469e-02 6.9004018e-04 1.9733779e-02 1.0359012e-02\n",
      "  2.4524017e-03 1.2818663e-03 1.2270952e-02 2.2695551e-03 1.0533319e-01\n",
      "  1.7024240e-01 7.8606997e-03 1.7956983e-02 2.0610053e-02 5.1579297e-01]\n",
      " [3.9771909e-01 6.5087509e-01 4.3916300e-01 2.3826581e-01 3.2411438e-01\n",
      "  4.6929896e-01 5.6332964e-01 4.5645911e-01 1.1285289e-01 1.9790517e-01\n",
      "  5.2837916e-03 2.6853201e-03 1.8878145e-03 3.8372127e-03 4.2474237e-03\n",
      "  1.5914055e-03 2.3122712e-03 4.4010924e-03 2.7509305e-01 7.5809103e-03\n",
      "  4.8044147e-03 3.5881207e-03 1.5113264e-03 6.3503149e-04 5.6665337e-01\n",
      "  1.8790988e-02 4.2701536e-03 8.5225161e-03 7.2963891e-04 1.6405111e-02]\n",
      " [6.3112724e-01 4.7805014e-01 4.1215324e-01 9.9348441e-02 1.9270043e-01\n",
      "  7.0542997e-01 4.5462221e-01 4.2997396e-01 2.2061114e-01 3.0477968e-01\n",
      "  7.7536292e-03 3.1222547e-03 1.9102831e-03 6.0180826e-03 2.2914133e-03\n",
      "  4.6955612e-03 3.7736509e-03 6.9671529e-03 3.4356844e-01 2.5895773e-03\n",
      "  9.6747343e-04 3.2366079e-03 1.3682389e-03 1.5522166e-03 4.9770910e-01\n",
      "  2.5655344e-02 5.3435043e-03 3.5018433e-02 1.9784782e-03 9.3930336e-03]], shape=(5, 30), dtype=float32)\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=0.3977191>, <tf.Tensor: shape=(), dtype=float32, numpy=0.46929896>, <tf.Tensor: shape=(), dtype=float32, numpy=0.63112724>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70543>, <tf.Tensor: shape=(), dtype=float32, numpy=0.40888035>, <tf.Tensor: shape=(), dtype=float32, numpy=0.3977191>, <tf.Tensor: shape=(), dtype=float32, numpy=0.46929896>, <tf.Tensor: shape=(), dtype=float32, numpy=0.63112724>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70543>]\n",
      "Final Box:  [[90, 105, 143, 178, \"['person']\"], [101, 120, 126, 164, \"['person']\"], [132, 119, 154, 162, \"['person']\"], [117, 107, 167, 175, \"['person']\"], [0, 88, 38, 139, \"['tvmonitor']\"], [90, 105, 143, 178, \"['person']\"], [101, 120, 126, 164, \"['person']\"], [132, 119, 154, 162, \"['person']\"], [117, 107, 167, 175, \"['person']\"]]\n",
      "tf.Tensor([3 1 4], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(test_path):\n",
    "    model_test(filename)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "837cb654-ef70-4804-98d3-e83fe7face04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Object Found.\n",
      "No Object Found.\n",
      "No Object Found.\n",
      "No Object Found.\n",
      "No Object Found.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(test_path):\n",
    "    model_test(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7090dc-ab38-453b-9a0d-b0dffcb6f231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
